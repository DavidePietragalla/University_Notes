{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 107555,
          "databundleVersionId": 13033998,
          "sourceType": "competition"
        }
      ],
      "dockerImageVersionId": 31089,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# FDS Challenge: Starter Notebook\n",
        "\n",
        "This notebook will guide you through the first steps of the competition. Our goal here is to show you how to:\n",
        "\n",
        "1.  Load the `train.jsonl` and `test.jsonl` files from the competition data.\n",
        "2.  Create a very simple set of features from the data.\n",
        "3.  Train a basic model.\n",
        "4.  Generate a `submission.csv` file in the correct format.\n",
        "5.  Submit your results.\n",
        "\n",
        "Let's get started!"
      ],
      "metadata": {
        "id": "fIW167yCFdgy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Load the train.jsonl and test.jsonl Files from the Competition Data"
      ],
      "metadata": {
        "id": "Wq7m1FRoq8TU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Added to mount drive ---\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import json\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# --- Define the path to our data ---\n",
        "COMPETITION_NAME = 'fds-pokemon-battles-prediction-2025'\n",
        "DATA_PATH = os.path.join('/content/drive/MyDrive', COMPETITION_NAME)\n",
        "train_file_path = os.path.join(DATA_PATH, 'train.jsonl')\n",
        "test_file_path = os.path.join(DATA_PATH, 'test.jsonl')\n",
        "\n",
        "# Read the file line by line\n",
        "train_data = []\n",
        "print(f\"Loading data from '{train_file_path}'...\")\n",
        "try:\n",
        "    with open(train_file_path, 'r') as f:\n",
        "        for line in f:\n",
        "            # json.loads() parses one line (one JSON object) into a Python dictionary\n",
        "            train_data.append(json.loads(line))\n",
        "    print(f\"Successfully loaded {len(train_data)} battles.\")\n",
        "\n",
        "    # Let's inspect the first battle to see its structure\n",
        "    print(\"\\n--- Structure of the first train battle: ---\")\n",
        "    if train_data:\n",
        "        first_battle = train_data[0]\n",
        "\n",
        "        # To keep the output clean, we can create a copy and truncate the timeline\n",
        "        battle_for_display = first_battle.copy()\n",
        "        battle_for_display['battle_timeline'] = battle_for_display.get('battle_timeline', [])[-2:] # Show first 2 turns\n",
        "\n",
        "        # Use json.dumps for pretty-printing the dictionary\n",
        "        print(json.dumps(battle_for_display, indent=4))\n",
        "        if len(first_battle.get('battle_timeline', [])) > 3:\n",
        "            print(\"    ...\")\n",
        "            print(\"    (battle_timeline has been truncated for display)\")\n",
        "\n",
        "\n",
        "except FileNotFoundError:\n",
        "    print(f\"ERROR: Could not find the training file at '{train_file_path}'.\")\n",
        "    print(\"Please make sure you have added the competition data to this notebook.\")\n",
        "\n",
        "# Drop the batte 4877 which is wrong\n",
        "train_data = [battle for battle in train_data if battle.get(\"battle_id\") != 4877]"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-12T16:36:52.931004Z",
          "iopub.execute_input": "2025-10-12T16:36:52.931767Z",
          "iopub.status.idle": "2025-10-12T16:36:59.265177Z",
          "shell.execute_reply.started": "2025-10-12T16:36:52.931713Z",
          "shell.execute_reply": "2025-10-12T16:36:59.264224Z"
        },
        "id": "Chc_wW7xFdhB"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.5 Supporting Functions and Structures"
      ],
      "metadata": {
        "id": "p_vgXVzOupyl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def avg_effectiveness_moves(battle):\n",
        "  \"\"\"\n",
        "  Add to the features the average effectivness of the moves of the surviving p1 pokemons relative to p2 lead (if it is still conscious at the end of timeline)\n",
        "  \"\"\"\n",
        "\n",
        "  type_chart = {\n",
        "    \"Normal\": {\n",
        "        \"Rock\": 0.5, \"Steel\": 0.5, \"Ghost\": 0,\n",
        "    },\n",
        "    \"Fire\": {\n",
        "        \"Fire\": 0.5, \"Water\": 0.5, \"Grass\": 2, \"Ice\": 2,\n",
        "        \"Bug\": 2, \"Rock\": 0.5, \"Dragon\": 0.5, \"Steel\": 2,\n",
        "    },\n",
        "    \"Water\": {\n",
        "        \"Fire\": 2, \"Water\": 0.5, \"Grass\": 0.5, \"Rock\": 2, \"Ground\": 2, \"Dragon\": 0.5,\n",
        "    },\n",
        "    \"Grass\": {\n",
        "        \"Fire\": 0.5, \"Water\": 2, \"Grass\": 0.5, \"Poison\": 0.5,\n",
        "        \"Ground\": 2, \"Flying\": 0.5, \"Bug\": 0.5, \"Rock\": 2,\n",
        "        \"Dragon\": 0.5, \"Steel\": 0.5,\n",
        "    },\n",
        "    \"Electric\": {\n",
        "        \"Water\": 2, \"Grass\": 0.5, \"Electric\": 0.5, \"Ground\": 0,\n",
        "        \"Flying\": 2, \"Dragon\": 0.5,\n",
        "    },\n",
        "    \"Ice\": {\n",
        "        \"Fire\": 0.5, \"Water\": 0.5, \"Grass\": 2, \"Ice\": 0.5,\n",
        "        \"Ground\": 2, \"Flying\": 2, \"Dragon\": 2, \"Steel\": 0.5,\n",
        "    },\n",
        "    \"Fighting\": {\n",
        "        \"Normal\": 2, \"Ice\": 2, \"Rock\": 2, \"Dark\": 2, \"Steel\": 2,\n",
        "        \"Poison\": 0.5, \"Flying\": 0.5, \"Psychic\": 0.5, \"Bug\": 0.5,\n",
        "        \"Ghost\": 0, \"Fairy\": 0.5,\n",
        "    },\n",
        "    \"Poison\": {\n",
        "        \"Grass\": 2, \"Poison\": 0.5, \"Ground\": 0.5, \"Rock\": 0.5,\n",
        "        \"Ghost\": 0.5, \"Steel\": 0, \"Fairy\": 2,\n",
        "    },\n",
        "    \"Ground\": {\n",
        "        \"Fire\": 2, \"Grass\": 0.5, \"Electric\": 2, \"Poison\": 2, \"Rock\": 2,\n",
        "        \"Bug\": 0.5, \"Flying\": 0, \"Steel\": 2,\n",
        "    },\n",
        "    \"Flying\": {\n",
        "        \"Grass\": 2, \"Fighting\": 2, \"Bug\": 2, \"Rock\": 0.5,\n",
        "        \"Electric\": 0.5, \"Steel\": 0.5,\n",
        "    },\n",
        "    \"Psychic\": {\n",
        "        \"Fighting\": 2, \"Poison\": 2, \"Steel\": 0.5, \"Psychic\": 0.5, \"Dark\": 0,\n",
        "    },\n",
        "    \"Bug\": {\n",
        "        \"Grass\": 2, \"Psychic\": 2, \"Dark\": 2, \"Fire\": 0.5, \"Fighting\": 0.5,\n",
        "        \"Poison\": 0.5, \"Flying\": 0.5, \"Ghost\": 0.5, \"Steel\": 0.5,\n",
        "        \"Fairy\": 0.5,\n",
        "    },\n",
        "    \"Rock\": {\n",
        "        \"Fire\": 2, \"Ice\": 2, \"Flying\": 2, \"Bug\": 2,\n",
        "        \"Fighting\": 0.5, \"Ground\": 0.5, \"Steel\": 0.5,\n",
        "    },\n",
        "    \"Ghost\": {\n",
        "        \"Normal\": 0, \"Psychic\": 2, \"Ghost\": 2, \"Dark\": 0.5,\n",
        "    },\n",
        "    \"Dragon\": {\n",
        "        \"Dragon\": 2, \"Steel\": 0.5, \"Fairy\": 0,\n",
        "    },\n",
        "    \"Dark\": {\n",
        "        \"Psychic\": 2, \"Ghost\": 2, \"Fighting\": 0.5, \"Dark\": 0.5, \"Fairy\": 0.5,\n",
        "    },\n",
        "    \"Steel\": {\n",
        "        \"Fire\": 0.5, \"Water\": 0.5, \"Electric\": 0.5, \"Ice\": 2,\n",
        "        \"Rock\": 2, \"Fairy\": 2, \"Steel\": 0.5,\n",
        "    },\n",
        "    \"Fairy\": {\n",
        "        \"Fighting\": 2, \"Dragon\": 2, \"Dark\": 2, \"Fire\": 0.5,\n",
        "        \"Poison\": 0.5, \"Steel\": 0.5,\n",
        "    },\n",
        "}\n",
        "\n",
        "  p1_team_details = {pokemon.get('name', f'p1_unknown_{i}'):\n",
        "    {\n",
        "      'hp': 1.00,\n",
        "      'types': pokemon.get('types'),\n",
        "      'moves': []\n",
        "    } for i, pokemon in enumerate(battle.get('p1_team_details', []))}\n",
        "\n",
        "  p2_lead_details = {\n",
        "      'name' : battle.get('p2_lead_details', {}).get('name'),\n",
        "      'hp' : 1.00,\n",
        "      'types' : battle.get('p2_lead_details', {}).get('types')\n",
        "  }\n",
        "\n",
        "  for turn in battle.get('battle_timeline', []):\n",
        "\n",
        "    p1_state = turn.get('p1_pokemon_state', {})\n",
        "    p1_name = p1_state.get('name')\n",
        "    if p1_name in p1_team_details:\n",
        "        if 'hp_pct' in p1_state:\n",
        "            p1_team_details[p1_name]['hp'] = p1_state['hp_pct']\n",
        "\n",
        "    move_details = turn.get('p1_move_details')\n",
        "    if move_details:\n",
        "        move_name = move_details.get('name')\n",
        "        already_known = any(m.get('name') == move_name for m in p1_team_details[p1_name]['moves'])\n",
        "        if not already_known:\n",
        "            p1_team_details[p1_name]['moves'].append(move_details)\n",
        "\n",
        "    p2_state = turn.get('p2_pokemon_state', {})\n",
        "    if p2_state.get('name') == p2_lead_details['name']:\n",
        "      p2_lead_details['hp'] = p2_state['hp_pct']\n",
        "\n",
        "  # Check of the lead pokemon\n",
        "  if p2_lead_details['hp'] == 0:\n",
        "    return 0\n",
        "  else:\n",
        "    total_effectiveness = 0\n",
        "    move_count = 0\n",
        "\n",
        "    # Types of the lead of p2\n",
        "    p2_types = p2_lead_details.get('types', [])\n",
        "\n",
        "    for p1_name, p1_data in p1_team_details.items():\n",
        "      # Only not fainted pokemons\n",
        "      if p1_data['hp'] > 0:\n",
        "        for move in p1_data['moves']:\n",
        "          if move['base_power'] == 0:\n",
        "            continue\n",
        "          else:\n",
        "            move_type = move.get('type')\n",
        "            multiplier = 1.0\n",
        "            for target_type in p2_types:\n",
        "                multiplier *= type_chart.get(move_type, {}).get(target_type, 1.0)\n",
        "\n",
        "            total_effectiveness += multiplier\n",
        "            move_count += 1\n",
        "\n",
        "    if move_count == 0:\n",
        "        return 0\n",
        "\n",
        "    avg_effectiveness = total_effectiveness / move_count\n",
        "    return avg_effectiveness\n",
        "\n",
        "def create_pokemon_stats_dict(data_list: list[dict]):\n",
        "    \"\"\"\n",
        "    Iterates through a list of battle data and extracts the base stats and types\n",
        "    for every unique Pokémon, returning a dictionary mapping name to stats and types\n",
        "    \"\"\"\n",
        "    pokemon_stats = {}\n",
        "\n",
        "    for battle in data_list:\n",
        "        # Check P1 team details\n",
        "        pokemon_list = battle.get('p1_team_details', [])\n",
        "        for pokemon in pokemon_list:\n",
        "            name = pokemon.get('name')\n",
        "            lvl = pokemon.get('level')\n",
        "            if name and name not in pokemon_stats and lvl==100:\n",
        "                # Extract all base stats\n",
        "                stats = {k: v for k, v in pokemon.items() if k.startswith('base_')}\n",
        "\n",
        "                # Add the types\n",
        "                stats['types'] = pokemon.get('types', ['notype', 'notype'])\n",
        "\n",
        "                if stats:\n",
        "                    pokemon_stats[name] = stats\n",
        "    return pokemon_stats\n",
        "\n",
        "def track_pokemon_conditions(battle):\n",
        "    \"\"\"\n",
        "    Iterates through the timeline of a battle to track the conditions of each Pokémon\n",
        "    \"\"\"\n",
        "    # Initialize the data structure\n",
        "    p1_pok_cond = {pokemon.get('name', f'p1_unknown_{i}'):\n",
        "    {\n",
        "      'hp': 1.00,\n",
        "      'status': 'nostatus'\n",
        "    } for i, pokemon in enumerate(battle.get('p1_team_details', []))}\n",
        "    p2_pok_cond = {}\n",
        "    p2_pok_cond[battle.get('p2_lead_details', {}).get('name')] = {\n",
        "      'hp': 1.00,\n",
        "      'status': 'nostatus'\n",
        "    }\n",
        "\n",
        "    # Fill the values with the latest conditions shown in the timeline\n",
        "    for turn in battle.get('battle_timeline', []):\n",
        "      p1_pok_cond[turn.get('p1_pokemon_state', {}).get('name')] = {\n",
        "          'hp': turn.get('p1_pokemon_state', {}).get('hp_pct'),\n",
        "          'status': turn.get('p1_pokemon_state', {}).get('status')\n",
        "      }\n",
        "      p2_pok_cond[turn.get('p2_pokemon_state', {}).get('name')] = {\n",
        "          'hp': turn.get('p2_pokemon_state', {}).get('hp_pct'),\n",
        "          'status': turn.get('p2_pokemon_state', {}).get('status')\n",
        "      }\n",
        "\n",
        "    # Compute the number of pokemon changes for each player (indicator of strategy)\n",
        "    p1_n_changes = 0\n",
        "    p2_n_changes = 0\n",
        "    for turn in battle.get('battle_timeline', []):\n",
        "      p1_current_pok = turn.get('p1_pokemon_state', {}).get('name')\n",
        "      p2_current_pok = turn.get('p2_pokemon_state', {}).get('name')\n",
        "      if turn != battle.get('battle_timeline', [])[0]:\n",
        "        if p1_pre_pok != p1_current_pok:\n",
        "          p1_n_changes += 1\n",
        "        if p2_pre_pok != p2_current_pok:\n",
        "          p2_n_changes += 1\n",
        "      else:\n",
        "        p1_pre_pok = p1_current_pok\n",
        "        p2_pre_pok = p2_current_pok\n",
        "\n",
        "    # Compute the number of effects working on the last round and weigh them\n",
        "    p1_effects = len(battle.get('battle_timeline', [])[-1].get('p1_pokemon_state', {}).get('effects', []))*0.4\n",
        "    p2_effects = len(battle.get('battle_timeline', [])[-1].get('p2_pokemon_state', {}).get('effects', []))*0.4\n",
        "\n",
        "    # Add the slots corresponding to the unseen pokemons of player #2\n",
        "    for i in range(len(p2_pok_cond), 6):\n",
        "      p2_pok_cond[f'p2_unknown_{i}'] = {\n",
        "          'hp': 1.00,\n",
        "          'status': 'nostatus'\n",
        "      }\n",
        "    return p1_n_changes, p1_effects, p1_pok_cond, p2_n_changes, p2_effects, p2_pok_cond\n",
        "\n",
        "def compute_differences_base_stats(p1_pok_cond, p2_pok_cond, pokemon_dict):\n",
        "  \"\"\"\n",
        "  Calculates the difference in total base stats between player #1 and player #2\n",
        "  \"\"\"\n",
        "  p1_total_speed = 0\n",
        "  p2_total_speed = 0\n",
        "  p1_total_attack = 0\n",
        "  p2_total_attack = 0\n",
        "  p1_total_defense = 0\n",
        "  p2_total_defense = 0\n",
        "  p1_total_sp_attack = 0\n",
        "  p2_total_sp_attack = 0\n",
        "  p1_total_sp_defense = 0\n",
        "  p2_total_sp_defense = 0\n",
        "  p1_total_hp = 0\n",
        "  p2_total_hp = 0\n",
        "  for pokemon in p1_pok_cond.keys():\n",
        "    if pokemon in pokemon_dict:\n",
        "      p1_total_speed += pokemon_dict[pokemon]['base_spe']\n",
        "      p1_total_attack += pokemon_dict[pokemon]['base_atk']\n",
        "      p1_total_defense += pokemon_dict[pokemon]['base_def']\n",
        "      p1_total_sp_attack += pokemon_dict[pokemon]['base_spa']\n",
        "      p1_total_sp_defense += pokemon_dict[pokemon]['base_spd']\n",
        "      p1_total_hp += pokemon_dict[pokemon]['base_hp']\n",
        "  for pokemon in p2_pok_cond.keys():\n",
        "    if pokemon in pokemon_dict:\n",
        "      p2_total_speed += pokemon_dict[pokemon]['base_spe']\n",
        "      p2_total_attack += pokemon_dict[pokemon]['base_atk']\n",
        "      p2_total_defense += pokemon_dict[pokemon]['base_def']\n",
        "      p2_total_sp_attack += pokemon_dict[pokemon]['base_spa']\n",
        "      p2_total_sp_defense += pokemon_dict[pokemon]['base_spd']\n",
        "      p2_total_hp += pokemon_dict[pokemon]['base_hp']\n",
        "  speed = p1_total_speed-p2_total_speed\n",
        "  defense = p1_total_defense-p2_total_defense\n",
        "  attack = p1_total_attack-p2_total_attack\n",
        "  sp_attack = p1_total_sp_attack-p2_total_sp_attack\n",
        "  sp_defense = p1_total_sp_defense-p2_total_sp_defense\n",
        "  hp = p1_total_hp-p2_total_hp\n",
        "  return speed, defense, attack, sp_attack, sp_defense, hp\n",
        "\n",
        "# TO BE REMOVED\n",
        "def get_all_statuses(data: list[dict]):\n",
        "    all_statuses = set()\n",
        "\n",
        "    for battle in tqdm(data, desc=\"Scanning for statuses\"):\n",
        "        for turn in battle.get('battle_timeline', []):\n",
        "            p1_state = turn.get('p1_move_details')\n",
        "            if p1_state and 'name' in p1_state:\n",
        "                all_statuses.add(p1_state['name'])\n",
        "            p2_state = turn.get('p2_move_details')\n",
        "            if p2_state and 'name' in p2_state:\n",
        "                all_statuses.add(p2_state['name'])\n",
        "    print(all_statuses)\n",
        "    return all_statuses"
      ],
      "metadata": {
        "id": "_FnIh_otuytf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Basic Feature Engineering\n",
        "\n",
        "A successful model will likely require creating many complex features. For this starter notebook, however, we will create a very simple feature set based **only on the initial team stats**. This will be enough to train a model and generate a submission file.\n",
        "\n",
        "It's up to you to engineer more powerful features!"
      ],
      "metadata": {
        "id": "wIHgPSVcFdhD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm.notebook import tqdm\n",
        "import numpy as np\n",
        "\n",
        "def create_features(data: list[dict]) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Extracts features based on the battle timeline.\n",
        "    Features currently include:\n",
        "    - Mean remaining HP percentage for Player 1's team.\n",
        "    - Mean remaining HP percentage for Player 2's team.\n",
        "    - Number of surviving Pokemon (HP > 0) for Player 1.\n",
        "    - Number of surviving Pokemon (HP > 0) for Player 2.\n",
        "    \"\"\"\n",
        "    feature_list = []\n",
        "\n",
        "    # Creating a dictionary of pokemons along with stats in the dataset\n",
        "    pokemon_dict = create_pokemon_stats_dict(data)\n",
        "\n",
        "    # For each battle\n",
        "    for battle in tqdm(data, desc=\"Extracting features\"):\n",
        "        features = {}\n",
        "        timeline = battle.get('battle_timeline', [])\n",
        "\n",
        "        # Track the conditions of teams at the end of the timeline\n",
        "        # Track the number of changes of each trainer\n",
        "        # Track the number of effects\n",
        "        p1_n_changes, p1_effects, p1_pok_cond, p2_n_changes, p2_effects, p2_pok_cond = track_pokemon_conditions(battle)\n",
        "\n",
        "        # Add to the features the average effectiveness\n",
        "        # avg_effectiveness = avg_effectiveness_moves(battle)\n",
        "        # features['avg_effectiveness'] = avg_effectiveness\n",
        "\n",
        "        # Add to the features the mean of the percentage of HP for each team\n",
        "        p1_mean_pc_hp = np.mean([info['hp'] for info in p1_pok_cond.values()])\n",
        "        p2_mean_pc_hp = np.mean([info['hp'] for info in p2_pok_cond.values()])\n",
        "        features['p1_mean_pc_hp'] = p1_mean_pc_hp\n",
        "        features['p2_mean_pc_hp'] = p2_mean_pc_hp\n",
        "\n",
        "        # Add to the features the number of surviving pokemon for each team\n",
        "        p1_surviving_pokemon = sum(1 for info in p1_pok_cond.values() if info[\"hp\"] > 0)\n",
        "        p2_surviving_pokemon = sum(1 for info in p2_pok_cond.values() if info[\"hp\"] > 0)\n",
        "        features['p1_surviving_pokemon'] = p1_surviving_pokemon\n",
        "        features['p2_surviving_pokemon'] = p2_surviving_pokemon\n",
        "\n",
        "        # Add to the features the number of pokemon affected by status and an effect index for each team\n",
        "        p1_status_score = sum(1 for i in p1_pok_cond.values() if i['hp'] > 0 and i['status'] != 'nostatus')+p1_effects\n",
        "        p2_status_score = sum(1 for i in p2_pok_cond.values() if i['hp'] > 0 and i['status'] != 'nostatus')+p2_effects\n",
        "        features['p1_status_score'] = p1_status_score\n",
        "        features['p2_status_score'] = p2_status_score\n",
        "\n",
        "        # Add to the features not the mean but simply the difference\n",
        "        # Also some of them could not be chosen because there is redundance in the pattern of stats distribution\n",
        "        speed, defense, attack, sp_attack, sp_defense, hp = compute_differences_base_stats(p1_pok_cond, p2_pok_cond, pokemon_dict)\n",
        "        features['total_speed_difference'] = speed #47\n",
        "        features['total_attack_difference'] = attack # 40\n",
        "        features['total_defense_difference'] = defense # 19\n",
        "        features['total_sp_attack_difference'] = sp_attack # 24\n",
        "        features['total_sp_defense_difference'] = sp_defense # 24\n",
        "        features['total_hp_difference'] = hp # 24\n",
        "\n",
        "        # Add to the features the number of pokemon changes along the timeline for each team (indicator of strategy)\n",
        "        #features['p1_n_changes'] = p1_n_changes\n",
        "        #features['p2_n_changes'] = p2_n_changes\n",
        "\n",
        "        # Add to the features the battle id and the true outcome of the battle\n",
        "        features['battle_id'] = battle.get('battle_id')\n",
        "        # Include target variable if in data\n",
        "        if 'player_won' in battle:\n",
        "            features['player_won'] = int(battle['player_won'])\n",
        "\n",
        "        # Append all features to the list\n",
        "        feature_list.append(features)\n",
        "\n",
        "    # Convert to DataFrame and handle missing values introduced by get()\n",
        "    return pd.DataFrame(feature_list).fillna(0)\n",
        "\n",
        "# Create feature DataFrames for both training and test sets\n",
        "print(\"Processing training data...\")\n",
        "train_df = create_features(train_data)\n",
        "\n",
        "print(\"\\nProcessing test data...\")\n",
        "test_data = []\n",
        "with open(test_file_path, 'r') as f:\n",
        "    for line in f:\n",
        "        test_data.append(json.loads(line))\n",
        "test_df = create_features(test_data)\n",
        "\n",
        "print(\"\\nTraining features preview:\")\n",
        "display(train_df.head())"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-12T17:32:42.773390Z",
          "iopub.execute_input": "2025-10-12T17:32:42.777152Z",
          "iopub.status.idle": "2025-10-12T17:32:51.378058Z",
          "shell.execute_reply.started": "2025-10-12T17:32:42.777053Z",
          "shell.execute_reply": "2025-10-12T17:32:51.376695Z"
        },
        "id": "01Y8B5upFdhE"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Training a Baseline Model\n",
        "\n",
        "Now that we have some features, let's train a simple `LogisticRegression` model. This will give us a starting point for our predictions."
      ],
      "metadata": {
        "id": "okM3iD2QFdhF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# Define our features (X) and target (y)\n",
        "features = [col for col in train_df.columns if col not in ['battle_id', 'player_won']]\n",
        "X = train_df[features]\n",
        "y = train_df['player_won']\n",
        "\n",
        "# Define the test set\n",
        "X_test = test_df[features].copy()\n",
        "\n",
        "# Set up cross validation\n",
        "# [Lines to uncomment K validation]\n",
        "N_SPLITS = 5\n",
        "skf = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=42)\n",
        "\n",
        "val_scores1 = []\n",
        "val_scores3 = []\n",
        "train_scores1 = []\n",
        "train_scores3 = []\n",
        "test_predictions_list1 = []\n",
        "test_predictions_list3 = []\n",
        "print(f\"Starting of {N_SPLITS}-fold cross-validation...\")\n",
        "for fold, (train_index, val_index) in enumerate(skf.split(X, y)):\n",
        "    print(f\"\\n--- Fold {fold+1}/{N_SPLITS} ---\")\n",
        "\n",
        "    # Splitting for this fold\n",
        "    X_train_fold, X_val_fold = X.iloc[train_index], X.iloc[val_index]\n",
        "    y_train_fold, y_val_fold = y.iloc[train_index], y.iloc[val_index]\n",
        "\n",
        "    # Normalization\n",
        "    scaler = StandardScaler()\n",
        "    X_train_fold = pd.DataFrame(scaler.fit_transform(X_train_fold), columns=features, index=X_train_fold.index)\n",
        "    X_val_fold = pd.DataFrame(scaler.transform(X_val_fold), columns=features, index=X_val_fold.index)\n",
        "    X_test_scaled = pd.DataFrame(scaler.transform(X_test), columns=features, index=X_test.index)\n",
        "\n",
        "    # Training\n",
        "    # ATTENTION for having model 2 instead of model 3, uncomment n_changes features in the feature section\n",
        "    model1 = LogisticRegression(\n",
        "        C=0.11,\n",
        "        penalty='l2',\n",
        "        solver='liblinear',\n",
        "        random_state=42,\n",
        "        max_iter=1000,\n",
        "        class_weight=None\n",
        "    )\n",
        "    model3 = GradientBoostingClassifier(learning_rate=0.1, max_depth=3, n_estimators=200,random_state=42)\n",
        "    model1.fit(X_train_fold, y_train_fold)\n",
        "    model3.fit(X_train_fold, y_train_fold)\n",
        "    print(f\"End of #{fold+1} training.\")\n",
        "\n",
        "    # Predict on training data to get training AUC\n",
        "    train_proba1 = model1.predict_proba(X_train_fold)[:, 1]\n",
        "    fold_train_auc1 = roc_auc_score(y_train_fold, train_proba1)\n",
        "    train_proba3 = model3.predict_proba(X_train_fold)[:, 1]\n",
        "    fold_train_auc3 = roc_auc_score(y_train_fold, train_proba3)\n",
        "\n",
        "    # Validation\n",
        "    val_preds1 = model1.predict(X_val_fold)\n",
        "    val_proba1 = model1.predict_proba(X_val_fold)[:, 1]\n",
        "    val_preds3 = model3.predict(X_val_fold)\n",
        "    val_proba3 = model3.predict_proba(X_val_fold)[:, 1]\n",
        "\n",
        "    fold_accuracy1 = accuracy_score(y_val_fold, val_preds1)\n",
        "    fold_accuracy3 = accuracy_score(y_val_fold, val_preds3)\n",
        "    fold_auc1 = roc_auc_score(y_val_fold, val_proba1)\n",
        "    fold_auc3 = roc_auc_score(y_val_fold, val_proba3)\n",
        "    fold_precision1 = precision_score(y_val_fold, val_preds1)\n",
        "    fold_precision3 = precision_score(y_val_fold, val_preds3)\n",
        "    fold_recall1 = recall_score(y_val_fold, val_preds1)\n",
        "    fold_recall3 = recall_score(y_val_fold, val_preds3)\n",
        "    fold_f1_1 = f1_score(y_val_fold, val_preds1)\n",
        "    fold_f1_3 = f1_score(y_val_fold, val_preds3)\n",
        "    val_scores1.append({'accuracy': fold_accuracy1, 'auc': fold_auc1, 'precision': fold_precision1, 'recall': fold_recall1, 'f1': fold_f1_1})\n",
        "    val_scores3.append({'accuracy': fold_accuracy3, 'auc': fold_auc3, 'precision': fold_precision3, 'recall': fold_recall3, 'f1': fold_f1_3})\n",
        "\n",
        "    train_scores1.append({'auc': fold_train_auc1})\n",
        "    train_scores3.append({'auc': fold_train_auc3})\n",
        "    print(f\"Fold {fold+1} Accuracy Model 1: {fold_accuracy1:.4f}, Train AUC: {fold_train_auc1:.4f}, Val AUC: {fold_auc1:.4f}, Precision: {fold_precision1:.4f}, Recall: {fold_recall1:.4f}, F1: {fold_f1_1:.4f}\")\n",
        "    print(f\"Fold {fold+1} Accuracy Model 3: {fold_accuracy3:.4f}, Train AUC: {fold_train_auc3:.4f}, Val AUC: {fold_auc3:.4f}, Precision: {fold_precision3:.4f}, Recall: {fold_recall3:.4f}, F1: {fold_f1_3:.4f}\")\n",
        "\n",
        "    # Generating predictions\n",
        "    fold_test_preds1 = model1.predict_proba(X_test_scaled)[:, 1]\n",
        "    test_predictions_list1.append(fold_test_preds1)\n",
        "    fold_test_preds3 = model3.predict_proba(X_test_scaled)[:, 1]\n",
        "    test_predictions_list3.append(fold_test_preds3)\n",
        "\n",
        "# Printing of metrics\n",
        "print(\"\\n--- Cross-validation completed Model 1---\")\n",
        "mean_train_auc1 = np.mean([s['auc'] for s in train_scores1])\n",
        "mean_train_auc3 = np.mean([s['auc'] for s in train_scores3])\n",
        "mean_accuracy1 = np.mean([s['accuracy'] for s in val_scores1])\n",
        "mean_accuracy3 = np.mean([s['accuracy'] for s in val_scores3])\n",
        "mean_auc1 = np.mean([s['auc'] for s in val_scores1])\n",
        "mean_auc3 = np.mean([s['auc'] for s in val_scores3])\n",
        "mean_precision1 = np.mean([s['precision'] for s in val_scores1])\n",
        "mean_precision3 = np.mean([s['precision'] for s in val_scores3])\n",
        "mean_recall1 = np.mean([s['recall'] for s in val_scores1])\n",
        "mean_recall3 = np.mean([s['recall'] for s in val_scores3])\n",
        "mean_f1_1 = np.mean([s['f1'] for s in val_scores1])\n",
        "mean_f1_3 = np.mean([s['f1'] for s in val_scores3])\n",
        "print(f\"Average Training AUC: {mean_train_auc1:.4f}\")\n",
        "print(f\"Average Validation Accuracy: {mean_accuracy1:.4f}\")\n",
        "print(f\"Average Validation AUC: {mean_auc1:.4f}\")\n",
        "print(f\"Average Validation Precision: {mean_precision1:.4f}\")\n",
        "print(f\"Average Validation Recall: {mean_recall1:.4f}\")\n",
        "print(f\"Average Validation F1: {mean_f1_1:.4f}\")\n",
        "print(\"\\n--- Cross-validation completed Model 3---\")\n",
        "print(f\"Average Training AUC: {mean_train_auc3:.4f}\")\n",
        "print(f\"Average Validation Accuracy: {mean_accuracy3:.4f}\")\n",
        "print(f\"Average Validation AUC: {mean_auc3:.4f}\")\n",
        "print(f\"Average Validation Precision: {mean_precision3:.4f}\")\n",
        "print(f\"Average Validation Recall: {mean_recall3:.4f}\")\n",
        "print(f\"Average Validation F1: {mean_f1_3:.4f}\")\n",
        "# [Lines to uncomment K validation]"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-12T16:40:23.751414Z",
          "iopub.execute_input": "2025-10-12T16:40:23.751787Z",
          "iopub.status.idle": "2025-10-12T16:40:23.922363Z",
          "shell.execute_reply.started": "2025-10-12T16:40:23.751759Z",
          "shell.execute_reply": "2025-10-12T16:40:23.919195Z"
        },
        "id": "aj62JOOTFdhF"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Creating the Submission File\n",
        "\n",
        "The competition requires a `.csv` file with two columns: `battle_id` and `player_won`. Let's use our trained model to make predictions on the test set and format them correctly."
      ],
      "metadata": {
        "id": "pKpTx1oRFdhG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Generation of final predictions over the test set...\")\n",
        "\n",
        "# [Lines to uncomment K validation]\n",
        "# Compute the average of the k models\n",
        "average_test_proba1 = np.mean(test_predictions_list1, axis=0)\n",
        "average_test_proba3 = np.mean(test_predictions_list3, axis=0)\n",
        "\n",
        "# combined_average_proba = (average_test_proba1 + average_test_proba3) / 2.0\n",
        "# final_test_predictions = (combined_average_proba > 0.5).astype(int)\n",
        "\n",
        "# Convert to binary predictions\n",
        "final_test_predictions1 = (average_test_proba1 > 0.5).astype(int)\n",
        "final_test_predictions3 = (average_test_proba3 > 0.5).astype(int)\n",
        "# [Lines to uncomment K validation]\n",
        "\n",
        "# [Lines to comment K validation]\n",
        "# final_test_predictions = (test_predictions > 0.5).astype(int)\n",
        "# [Lines to comment K validation]\n",
        "\n",
        "# Create DataFrame for submission\n",
        "submission_df1 = pd.DataFrame({\n",
        "    'battle_id': test_df['battle_id'],\n",
        "    'player_won': final_test_predictions1\n",
        "})\n",
        "\n",
        "submission_df3 = pd.DataFrame({\n",
        "    'battle_id': test_df['battle_id'],\n",
        "    'player_won': final_test_predictions3\n",
        "})\n",
        "\n",
        "# Save the csv file\n",
        "submission_df1.to_csv('submission1.csv', index=False)\n",
        "submission_df3.to_csv('submission3.csv', index=False)\n",
        "\n",
        "\n",
        "print(\"\\n'submission.csv' file successfully created!\")\n",
        "display(submission_df1.head())\n",
        "display(submission_df3.head())"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-12T17:36:32.361652Z",
          "iopub.execute_input": "2025-10-12T17:36:32.362254Z",
          "iopub.status.idle": "2025-10-12T17:36:32.389548Z",
          "shell.execute_reply.started": "2025-10-12T17:36:32.362225Z",
          "shell.execute_reply": "2025-10-12T17:36:32.388135Z"
        },
        "id": "eVwAR7C3FdhG"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. Submitting Your Results\n",
        "\n",
        "Once you have generated your `submission.csv` file, there are two primary ways to submit it to the competition.\n",
        "\n",
        "---\n",
        "\n",
        "#### Method A: Submitting Directly from the Notebook\n",
        "\n",
        "This is the standard method for code competitions. It ensures that your submission is linked to the code that produced it, which is crucial for reproducibility.\n",
        "\n",
        "1.  **Save Your Work:** Click the **\"Save Version\"** button in the top-right corner of the notebook editor.\n",
        "2.  **Run the Notebook:** In the pop-up window, select **\"Save & Run All (Commit)\"** and then click the **\"Save\"** button. This will run your entire notebook from top to bottom and save the output, including your `submission.csv` file.\n",
        "3.  **Go to the Viewer:** Once the save process is complete, navigate to the notebook viewer page.\n",
        "4.  **Submit to Competition:** In the viewer, find the **\"Submit to Competition\"** section. This is usually located in the header of the output section or in the vertical \"...\" menu on the right side of the page. Clicking the **Submit** button this will submit your generated `submission.csv` file.\n",
        "\n",
        "After submitting, you will see your score in the **\"Submit to Competition\"** section or in the [Public Leaderboard](https://www.kaggle.com/competitions/fds-pokemon-battles-prediction-2025/leaderboard?).\n",
        "\n",
        "---\n",
        "\n",
        "#### Method B: Manual Upload\n",
        "\n",
        "You can also generate your predictions and submission file using any environment you prefer (this notebook, Google Colab, or your local machine).\n",
        "\n",
        "1.  **Generate the `submission.csv` file** using your model.\n",
        "2.  **Download the file** to your computer.\n",
        "3.  **Navigate to the [Leaderboard Page](https://www.kaggle.com/competitions/fds-pokemon-battles-prediction-2025/leaderboard?)** and click on the **\"Submit Predictions\"** button.\n",
        "4.  **Upload Your File:** Drag and drop or select your `submission.csv` file to upload it.\n",
        "\n",
        "This method is quick, but keep in mind that for the final evaluation, you might be required to provide the code that generated your submission.\n",
        "\n",
        "Good luck!"
      ],
      "metadata": {
        "id": "McHplgNSFdhH"
      }
    }
  ]
}
